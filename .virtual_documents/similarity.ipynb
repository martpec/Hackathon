import pandas as pd



# Load the CSV file (replace the path with your own file location)
df = pd.read_excel('data/filtered_only(3).xlsx')
# Show the first 5 rows
must_have_data = ['Actuator size', 'Actuator system [mm]','Coil connection', 'Cv value [gal/min]', 'Electrical connection', 'Enclosure rating IP', 'Frequency [Hz]', 'Function',  'Inlet connection type', 'Inlet size [in]', 'Inlet size [mm]', 'Kv value [m³/h]', 'Outlet connection type', 'Outlet size [in]', 'Outlet size [mm]','Refrigerants', 'Supply voltage 50Hz Max [V]', 'Supply voltage 50Hz Min [V]', 'Supply voltage 60Hz Max [V]', 'Supply voltage 60Hz Min [V]', 'Supply voltage [V] AC', 'Supply voltage [V] AC [max]', 'Supply voltage [V] AC [min]', 'Supply voltage [V] DC']

df[must_have_data] = df[must_have_data].fillna('BLANK').replace('', 'BLANK').replace(' ', 'BLANK')




columns = df.columns.tolist()
print(columns)

# valve to target - search similar to this one
target_index = 289
target_index2 = 291
target_row = df.iloc[target_index]
target_row2 = df.iloc[target_index2]
df = df.drop(index=target_index)

# remove first 14 values
df = df.iloc[14:]
print(len(df))


comparison = target_row == target_row2
matching_columns = comparison[comparison].index.tolist()
print("Matching columns:", matching_columns)



print(target_row)


mask = (df[must_have_data].fillna('NaN_placeholder')
        .eq(target_row[must_have_data].fillna('NaN_placeholder'))
        .all(axis=1))

# Get all matching rows
matching_rows = df[mask]


print(matching_rows)
len(matching_rows)


duplicates = df[df.duplicated(subset=must_have_data, keep=False)]
duplicates = duplicates.sort_values(by=must_have_data)

print(duplicates.iloc[0])
print(duplicates.iloc[1])


def numeric_similarity(a, b):
    if pd.isna(a) or pd.isna(b):
        return 0
    return 1 - abs(a - b) / max(abs(a), abs(b), 1e-9)

def categorical_similarity(a, b):
    return 1.0 if str(a).lower().strip() == str(b).lower().strip() else 0.0


def compute_similarity(item_a, item_b):
    total_weight = sum(FEATURE_WEIGHTS.values())
    score = 0

    for feature, weight in FEATURE_WEIGHTS.items():
        val_a = item_a.get(feature)
        val_b = item_b.get(feature)

        if isinstance(val_a, (int, float)) and isinstance(val_b, (int, float)):
            sim = numeric_similarity(val_a, val_b)
        else:
            sim = categorical_similarity(val_a, val_b)

        score += sim * weight

    return score / total_weight


selected_a = df_a.iloc[0].to_dict()
df_b["similarity"] = df_b.apply(lambda row: compute_similarity(selected_a, row.to_dict()), axis=1)
df_b_sorted = df_b.sort_values("similarity", ascending=False)

print("Top matches:\n", df_b_sorted[["id", "similarity"]])
best_match = df_b_sorted.iloc[0]
print("\n✅ Best match found:", best_match.to_dict())
